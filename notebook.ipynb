{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "## Imports"
   ],
   "id": "ff227841-b9ea-4e2f-bd4b-5670c9851136"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torchvision.utils as vutils\n",
    "from torchview import draw_graph\n"
   ],
   "id": "2e3fe80d-88a9-4ac0-b8a9-3bf8b24df406"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ],
   "id": "16a5fa82-6c05-40db-8cfc-6a476c1bf02e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "RESET = False\n",
    "\n",
    "IMG_H = IMG_W = 256\n",
    "RANDOM_SEED = 23                # mj\n",
    "K = 5\n",
    "STYLE_TOGGLE = True\n",
    "TUNING_TOGGLE = False\n"
   ],
   "id": "aa66ad62-dfb2-4de7-b405-8d295c46be34"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style"
   ],
   "id": "d8ea3c61-63db-4a9e-9dc1-0faba6fa01cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STYLE_TOGGLE:                        # Dark used to visualize in Emacs\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.rcParams.update({\n",
    "        \"figure.facecolor\": \"#282C34\",  # whole figure background\n",
    "        \"axes.facecolor\": \"#282C34\",    # axes background\n",
    "        \"axes.edgecolor\": \"white\",\n",
    "        \"axes.labelcolor\": \"white\",\n",
    "        \"xtick.color\": \"white\",\n",
    "        \"ytick.color\": \"white\",\n",
    "        \"text.color\": \"white\",\n",
    "        \"axes.titlecolor\": \"white\",\n",
    "        \"grid.color\": \"#444444\",\n",
    "        \"lines.linewidth\": 2,\n",
    "    })\n",
    "else:                                   # Light used for report\n",
    "    plt.style.use(\"default\")\n",
    "    plt.rcParams.update({\n",
    "        \"figure.facecolor\": \"white\",    # whole figure background\n",
    "        \"axes.facecolor\": \"white\",      # axes background\n",
    "        \"axes.edgecolor\": \"black\",\n",
    "        \"axes.labelcolor\": \"black\",\n",
    "        \"xtick.color\": \"black\",\n",
    "        \"ytick.color\": \"black\",\n",
    "        \"text.color\": \"black\",\n",
    "        \"axes.titlecolor\": \"black\",\n",
    "        \"grid.color\": \"#262626\",\n",
    "        \"lines.linewidth\": 2,\n",
    "    })\n"
   ],
   "id": "b27b6fd4-7025-466a-9af2-4955fe903e71"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info & Reproducibility"
   ],
   "id": "ac5a4b3a-87e1-415f-9c00-475cc338b7ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Currently using: {device}\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)                                          # Reproducibility\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"archive\", transform=transforms.ToTensor())\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "mean = diff = 0.0\n",
    "num_pixels = 0\n",
    "\n",
    "for image, _ in loader:\n",
    "    image = image.squeeze(0)                                            # Remove useless batch=1\n",
    "    mean += image.sum(dim=[1, 2])\n",
    "    num_pixels += image.shape[1] * image.shape[2]                       # Height * Width\n",
    "\n",
    "mean /= num_pixels\n",
    "\n",
    "for image, _ in loader:\n",
    "    image = image.squeeze(0)                                            # Remove useless batch=1\n",
    "    diff += ((image - mean.view(-1, 1, 1)) ** 2).sum(dim=[1, 2])\n",
    "\n",
    "std = (diff / num_pixels).sqrt()\n",
    "\n",
    "print(\"Dataset mean:\", mean)\n",
    "print(\"Dataset std:\", std)\n"
   ],
   "id": "12e1983d-12e0-4085-8394-d4dab5fe1355"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Architectures\n",
    "\n",
    "## Transform"
   ],
   "id": "3b58b765-cfda-4777-a7f6-6049b7272d8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_H, IMG_W)\n",
    "                    , interpolation=InterpolationMode.BICUBIC),         # Image Resizing using bicubic interpolation\n",
    "    transforms.RandomHorizontalFlip(),                                  # Randomly flip Horizontally (0.5)\n",
    "    transforms.RandomAffine(\n",
    "        degrees=90,                                                     # -90 and +90\n",
    "        scale=(0.85, 1.15),                                             # zoom 85% or zoom 115%\n",
    "    ),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),                                              # Scaling [0,255] -> [0,1]\n",
    "    transforms.Normalize(mean=mean,                                     # output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "                        std=std)\n",
    "])\n"
   ],
   "id": "16694a31-bf45-487e-bff6-ce85a9d7fa6d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures"
   ],
   "id": "7c9242ff-93bb-4191-a1f0-77fb600b07be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_First(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,   32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,  64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.ln1 = nn.Linear(128*32*32, 256)                            # After flattening\n",
    "        self.ln2 = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "\n",
    "class CNN_Second(CNN_First):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.dropout2d = nn.Dropout2d(p=0.1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "\n",
    "class CNN_Third(CNN_Second):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.ln1 = nn.Linear(256*16*16, 1024)\n",
    "        self.ln2 = nn.Linear(1024, 256)\n",
    "        self.ln3 = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.ln2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.ln3(x)\n",
    "        return x\n",
    "\n",
    "class CNN_Fourth(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.bn9 = nn.BatchNorm2d(512)\n",
    "        self.bn10 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.dropout2d = nn.Dropout2d(0.1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.ln1 = nn.Linear(512*8*8, 1024)\n",
    "        self.ln2 = nn.Linear(1024, 256)\n",
    "        self.ln3 = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        # Block 3\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        # Block 4\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        # Block 5\n",
    "        x = F.relu(self.bn9(self.conv9(x)))\n",
    "        x = F.relu(self.bn10(self.conv10(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2d(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.ln2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.ln3(x)\n",
    "        return x\n"
   ],
   "id": "294a8b68-25e6-4269-a75a-9f49e34cd5ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ],
   "id": "20c27eb0-a291-4415-932e-eef5b16e853f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=\"archive\", transform=transform)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    list(range(len(dataset))),\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=dataset.targets\n",
    ")\n",
    "\n",
    "train_subset = Subset(dataset, train_idx)\n",
    "test_subset = Subset(dataset, test_idx)\n",
    "\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "architecture = CNN_Fourth                                        # Change this to change architecture\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\": [1e-3, 5e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [10, 20, 30]\n",
    "}\n",
    "\n",
    "param_combinations = list(itertools.product(\n",
    "    hyperparams[\"lr\"],\n",
    "    hyperparams[\"batch_size\"],\n",
    "    hyperparams[\"epochs\"]\n",
    "))\n",
    "\n",
    "\n",
    "if TUNING_TOGGLE:\n",
    "    best_loss = float(\"inf\")\n",
    "    best_params = None\n",
    "\n",
    "    for lr, batch_size, epochs in param_combinations:\n",
    "        print(f\"Testing: lr={lr}, batch_size={batch_size}, epochs={epochs}\")\n",
    "        fold_losses = []\n",
    "        fold_f1s = []\n",
    "        fold_accuracies = []\n",
    "        fold_recalls = []\n",
    "        fold_precisions = []\n",
    "\n",
    "        train_losses_per_fold = []\n",
    "        val_losses_per_fold = []\n",
    "\n",
    "        for fold, (t_idx, v_idx) in enumerate(kf.split(train_subset)):\n",
    "\n",
    "            train_fold_subset = Subset(train_subset, t_idx)\n",
    "            val_fold_subset = Subset(train_subset, v_idx)\n",
    "\n",
    "            train_loader = DataLoader(train_fold_subset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_fold_subset, batch_size=batch_size)\n",
    "\n",
    "            model = architecture().to(device)\n",
    "            criterion = nn.CrossEntropyLoss()                           # default reduction='mean'\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "\n",
    "                for images, labels in train_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                train_loss /= len(train_fold_subset)\n",
    "                train_losses.append(train_loss)\n",
    "\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in val_loader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)                       # mean loss per batch\n",
    "                        val_loss += loss.item() * images.size(0)                # total loss for batch\n",
    "                        if (epoch == epochs - 1):\n",
    "                            preds = torch.argmax(outputs, dim=1)\n",
    "                            all_preds.extend(preds.cpu().numpy())\n",
    "                            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                val_loss /= len(val_fold_subset)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            fold_losses.append(val_loss)\n",
    "\n",
    "            train_losses_per_fold.append(train_losses)\n",
    "            val_losses_per_fold.append(val_losses)\n",
    "\n",
    "            cm = confusion_matrix(all_labels, all_preds, labels=list(range(3)))\n",
    "            TP = cm.diagonal()\n",
    "            FP = cm.sum(axis=0) - TP\n",
    "            FN = cm.sum(axis=1) - TP\n",
    "            TN = cm.sum() - (TP + FP + FN)\n",
    "\n",
    "            precision_per_class = TP / (TP + FP + 1e-8)\n",
    "            recall_per_class = TP / (TP + FN + 1e-8)\n",
    "            f1_per_class = 2 * precision_per_class * recall_per_class / (precision_per_class + recall_per_class + 1e-8)\n",
    "\n",
    "            precision_macro = precision_per_class.mean()\n",
    "            recall_macro = recall_per_class.mean()\n",
    "            f1_macro = f1_per_class.mean()\n",
    "            accuracy = TP.sum() / cm.sum()\n",
    "\n",
    "            fold_precisions.append(precision_macro)\n",
    "            fold_recalls.append(recall_macro)\n",
    "            fold_f1s.append(f1_macro)\n",
    "            fold_accuracies.append(accuracy)\n",
    "\n",
    "            print(f\"Fold {fold+1} | Loss: {val_loss:.4f}, \"\n",
    "            f\"Precision: {precision_macro:.4f}, \"\n",
    "            f\"Recall: {recall_macro:.4f}, \"\n",
    "            f\"F1: {f1_macro:.4f}, \"\n",
    "            f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        avg_cv_loss = sum(fold_losses) / K\n",
    "        avg_precisions = sum(fold_precisions) / K\n",
    "        avg_f1 = sum(fold_f1s) / K\n",
    "        avg_accuracy = sum(fold_accuracies) / K\n",
    "        avg_recall = sum(fold_recalls) / K\n",
    "\n",
    "        print(f\"Average CV | Loss: {avg_cv_loss:.4f}, \"\n",
    "        f\"Precision: {avg_precisions:.4f}, \"\n",
    "        f\"F1: {avg_f1:.4f}, \"\n",
    "        f\"Accuracy: {avg_accuracy:.4f}, \"\n",
    "        f\"Recall: {avg_recall:.4f}\\n\")\n",
    "\n",
    "        train_losses_per_fold = np.array(train_losses_per_fold)  # shape: (5, epochs)\n",
    "        val_losses_per_fold = np.array(val_losses_per_fold)\n",
    "\n",
    "        epochs_range = range(1, epochs+1)\n",
    "        num_folds = train_losses_per_fold.shape[0]\n",
    "\n",
    "        fold_colors = ['blue', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "        plt.figure(figsize=(16,9))\n",
    "\n",
    "        for fold in range(num_folds):\n",
    "            color = fold_colors[fold % len(fold_colors)]\n",
    "            plt.plot(epochs_range, train_losses_per_fold[fold], color=color, linestyle='dashdot', label=f'Train Fold {fold+1}')\n",
    "            plt.plot(epochs_range, val_losses_per_fold[fold], color=color, linestyle='solid', label=f'Val Fold {fold+1}')\n",
    "\n",
    "        plt.plot(epochs_range, train_losses_per_fold.mean(axis=0), color='black', linestyle='dashdot', linewidth=2, label='Train Mean')\n",
    "        plt.plot(epochs_range, val_losses_per_fold.mean(axis=0), color='black', linestyle='solid', linewidth=2, label='Val Mean')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'lr={lr}, batch_size={batch_size}, epochs={epochs}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        if avg_cv_loss < best_loss:\n",
    "            best_loss = avg_cv_loss\n",
    "            best_params = (lr, batch_size, epochs)\n",
    "\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(f\"Learning rate: {best_params[0]}\")\n",
    "    print(f\"Batch size: {best_params[1]}\")\n",
    "    print(f\"Epochs: {best_params[2]}\")\n",
    "    print(f\"Average CV loss: {best_loss:.4f}\")\n",
    "else:\n",
    "    best_params = [1e-4, 16, 30]\n",
    "\n",
    "final_model = architecture().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params[0])\n",
    "final_epochs = best_params[2]\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=best_params[1], shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=best_params[1])\n",
    "\n",
    "train_losses_final = []\n",
    "test_losses_final = []\n",
    "train_accuracies_final = []\n",
    "test_accuracies_final = []\n",
    "\n",
    "for epoch in range(final_epochs):\n",
    "    final_model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    epoch_train_loss /= len(train_subset)\n",
    "    train_losses_final.append(epoch_train_loss)\n",
    "    train_accuracies_final.append(correct_train / total_train)\n",
    "\n",
    "    final_model.eval()\n",
    "    epoch_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = final_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_test_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    epoch_test_loss /= len(test_subset)\n",
    "    test_losses_final.append(epoch_test_loss)\n",
    "    test_accuracies_final.append(correct_test / total_test)\n",
    "\n",
    "final_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "test_loss = 0.0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = final_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_subset)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=list(range(3)))\n",
    "TP = cm.diagonal()\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (TP + FP + FN)\n",
    "\n",
    "precision_per_class = TP / (TP + FP + 1e-8)\n",
    "recall_per_class = TP / (TP + FN + 1e-8)\n",
    "f1_per_class = 2 * precision_per_class * recall_per_class / (precision_per_class + recall_per_class + 1e-8)\n",
    "\n",
    "precision_macro = precision_per_class.mean()\n",
    "recall_macro = recall_per_class.mean()\n",
    "f1_macro = f1_per_class.mean()\n",
    "accuracy = TP.sum() / cm.sum()\n",
    "\n",
    "epochs_range = range(1, final_epochs+1)\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(epochs_range, train_losses_final, linestyle='dashdot', color='blue', label='Train Loss')\n",
    "plt.plot(epochs_range, test_losses_final, linestyle='solid', color='red', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curves (Loss)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(epochs_range, train_accuracies_final, linestyle='dashdot', color='blue', label='Train Acc')\n",
    "plt.plot(epochs_range, test_accuracies_final, linestyle='solid', color='red', label='Test Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curves (Loss)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final Test Set Performance:\")\n",
    "print(f\"Loss:      {test_loss:.4f}\")\n",
    "print(f\"Precision: {precision_macro:.4f}\")\n",
    "print(f\"Recall:    {recall_macro:.4f}\")\n",
    "print(f\"F1:        {f1_macro:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ],
   "id": "f4787589-e0a9-49ba-8123-e37ddb8a5dc5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization"
   ],
   "id": "340f21b1-e529-4907-9eeb-9a240139b24c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Generalize_Hands\"\n",
    "\n",
    "transformGen = transforms.Compose([\n",
    "    transforms.Resize((IMG_H, IMG_W)\n",
    "                      , interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean,\n",
    "                         std=std)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transformGen)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "final_model.eval()\n",
    "final_model.to(device)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = final_model(inputs)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "    all_results.append((inputs.cpu()[0], labels.item(), pred.item(), outputs.cpu()[0]))\n",
    "\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i, (img, true_label, pred_label, logits) in enumerate(all_results):\n",
    "    plt.subplot(1, len(all_results), i+1)\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-0.3229/0.2554, -0.5491/0.1014, -0.2601/0.1327],\n",
    "        std=[1/0.2554, 1/0.1014, 1/0.1327]\n",
    "    )\n",
    "    img_show = inv_normalize(img)\n",
    "    img_show = transforms.ToPILImage()(img_show)\n",
    "    plt.imshow(img_show)\n",
    "\n",
    "    color = \"green\" if pred_label == true_label else \"red\"\n",
    "\n",
    "    logits_text = \"\\n\".join([f\"{c}: {l:.2f}\" for c, l in zip(dataset.classes, logits)])\n",
    "    plt.title(f\"T: {dataset.classes[true_label]}\\nP: {dataset.classes[pred_label]}\\n{logits_text}\", fontsize=8, c=color)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "true_labels = [t for _, t, _, _ in all_results]\n",
    "pred_labels = [p for _, _, p, _ in all_results]\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset.classes)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ],
   "id": "041adc37-31cf-4932-9459-dfba2c5205d2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Architectures"
   ],
   "id": "54f07367-cdd3-4b3a-bd1c-d0fda21bc395"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_graph = draw_graph(CNN_Fourth(), input_size=(1,3,256,256))\n",
    "model_graph.visual_graph\n"
   ],
   "id": "19f2129a-8daa-4a81-8a3d-2ef757089cc2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset"
   ],
   "id": "96e70ff9-e1c5-40ac-9bf9-0896011c4911"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "file drawer",
    "session": "py"
   },
   "outputs": [],
   "source": [
    "if RESET:\n",
    "    %reset\n"
   ],
   "id": "cde079a3-3467-4cc3-ad30-4dd883fd2c2b"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
